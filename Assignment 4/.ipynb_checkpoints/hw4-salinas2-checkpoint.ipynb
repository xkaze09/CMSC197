{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587d4d83-c647-4957-bb8f-1985dcf02f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from email import policy\n",
    "from email.parser import BytesParser\n",
    "\n",
    "# Define paths\n",
    "folder_path = \"trec06p-cs280/data/\"\n",
    "labels_file = \"trec06p-cs280/labels\"\n",
    "\n",
    "# Load stop words from stop_words.txt\n",
    "stop_words = []\n",
    "with open(\"stop_words.txt\", \"r\") as f:\n",
    "    stop_word = f.read().splitlines()\n",
    "    stop_words = [word for word in stop_word]\n",
    "\n",
    "# Useless info to be removed from the email\n",
    "punctuations = r\"!\\\"#$%&'()*+,-./:;<=>?@[\\\\]^_`{|}~\"\n",
    "numbers = \"0123456789\"\n",
    "html_tags = re.compile(r\"<.*?>\")  # remove HTML tags\n",
    "esc_chars = re.compile(r\"[a-z][a-z][0-9]+\")  # remove escape characters\n",
    "\n",
    "# Function to clean the email by removing useless information\n",
    "def clean_email(message): \n",
    "    # Convert to lowercase\n",
    "    message = message.lower()\n",
    "    # Remove HTML tags\n",
    "    message = re.sub(html_tags, '', message)\n",
    "    # Remove symbols (punctuations)\n",
    "    message = message.translate(str.maketrans('', '', punctuations))\n",
    "    # Remove numbers\n",
    "    message = message.translate(str.maketrans('', '', numbers))\n",
    "    # Remove escape characters\n",
    "    message = re.sub(esc_chars, '', message)\n",
    "    # Remove non-alphabetic characters\n",
    "    message = re.sub(r'[^a-zA-Z\\s]', '', message)\n",
    "\n",
    "    # Remove stop words\n",
    "    words = message.split()\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "\n",
    "    # Rejoin words into a cleaned message\n",
    "    message = \" \".join(words)\n",
    "\n",
    "    # If the cleaned message is empty, add a placeholder\n",
    "    if not message.strip():\n",
    "        message = \"[No content after cleaning]\"\n",
    "    \n",
    "    return message\n",
    "\n",
    "\n",
    "# Function to get message from parsed email\n",
    "def get_message(parsed):\n",
    "    message = \"\"\n",
    "    # If email has attachments or is multipart\n",
    "    if parsed.is_multipart():\n",
    "        # Iterate over parts of the email\n",
    "        for part in parsed.walk():\n",
    "            # Only get the plain text part of the email\n",
    "            if part.get_content_type() == 'text/plain':\n",
    "                try:\n",
    "                    message = part.get_payload(decode=True).decode('ISO-8859-1', errors='replace')\n",
    "                except:\n",
    "                    message = \"[Could not decode message]\"\n",
    "                break\n",
    "    # If it's a simple email with no attachments\n",
    "    else:\n",
    "        try:\n",
    "            message = parsed.get_payload(decode=True).decode('ISO-8859-1', errors='replace')\n",
    "        except:\n",
    "            message = \"[Could not decode message]\"\n",
    "    \n",
    "    # If message is empty after parsing\n",
    "    if not message.strip():\n",
    "        message = \"[No message content]\"\n",
    "    \n",
    "    return message\n",
    "\n",
    "\n",
    "# Load labels into a dataframe\n",
    "labels_df = pd.read_csv(labels_file, sep=\" \", names=[\"category\", \"file_path\"])\n",
    "labels_df[\"file_path\"] = labels_df[\"file_path\"].apply(lambda x: x.split(\"/\")[-1])\n",
    "\n",
    "# Initialize the main dataframe for storing processed email data\n",
    "main_df = pd.DataFrame(columns=[\"folder\", \"file\", \"email_message\", \"category\"])\n",
    "\n",
    "# Get all folders except hidden/system files\n",
    "folders = [folder for folder in os.listdir(folder_path) if not folder.startswith('.')]\n",
    "\n",
    "# Loop through the filtered folders\n",
    "for folder in folders:\n",
    "    # Get all files in the folder, excluding hidden/system files like .DS_Store\n",
    "    files = [file for file in os.listdir(f\"{folder_path}/{folder}\") if not file.startswith('.')]\n",
    "    \n",
    "    for file in files:\n",
    "        # Process each email file\n",
    "        with open(f\"{folder_path}/{folder}/{file}\", \"rb\") as e_mail:  # Open in binary mode 'rb'\n",
    "            # Parse email\n",
    "            parsed_email = BytesParser(policy=policy.default).parse(e_mail)\n",
    "            # Get message from parsed email\n",
    "            message = get_message(parsed_email)\n",
    "            # Clean email message (remove useless info like HTML tags, URLs, headers, stop words, etc.)\n",
    "            message_no_stopwords = clean_email(message)\n",
    "            # Get the category of the email based on the labels dataframe\n",
    "            category_label = labels_df[labels_df[\"file_path\"] == file][\"category\"].values[0]\n",
    "            # Concatenate the data to the main_df dataframe\n",
    "            main_df = pd.concat([main_df, pd.DataFrame([[folder, file, message_no_stopwords, category_label]], columns=[\"folder\", \"file\", \"email_message\", \"category\"])], ignore_index=True)\n",
    "\n",
    "# Check and create a directory for saving preprocessed files if it doesn't exist\n",
    "if not os.path.exists('preprocessed_files'):\n",
    "    os.makedirs('preprocessed_files')\n",
    "\n",
    "# Save main_df as preprocessed_emails.csv\n",
    "main_df.to_csv(\"preprocessed_files/preprocessed_emails.csv\", index=False)\n",
    "\n",
    "# Reset the main_df to avoid memory overload\n",
    "main_df.drop(main_df.index, inplace=True)\n",
    "main_df = pd.DataFrame(columns=[\"folder\", \"file\", \"email_message\", \"category\"])\n",
    "\n",
    "# Load the preprocessed dataset\n",
    "df_main = pd.read_csv(\"preprocessed_files/preprocessed_emails.csv\")\n",
    "\n",
    "# Split the dataset into training and testing sets based on folders 0-70 (train) and 71-126 (test)\n",
    "train_df = df_main[df_main['folder'].astype(int) <= 70]\n",
    "test_df = df_main[df_main['folder'].astype(int) > 70]\n",
    "\n",
    "# Split training data into spam and ham\n",
    "train_spam_df = train_df[train_df['category'] == 1]\n",
    "train_ham_df = train_df[train_df['category'] == 0]\n",
    "\n",
    "# Display the dataframes\n",
    "print(\"Main Dataset:\")\n",
    "print(df_main.head())\n",
    "\n",
    "print(\"\\nTraining Set (Spam):\")\n",
    "print(train_spam_df.head())\n",
    "\n",
    "print(\"\\nTraining Set (Ham):\")\n",
    "print(train_ham_df.head())\n",
    "\n",
    "print(\"\\nTest Set:\")\n",
    "print(test_df.head())\n",
    "\n",
    "# Initialize a Counter object to keep track of word frequencies\n",
    "word_counter = Counter()\n",
    "\n",
    "# Iterate over the training dataframe and update word counts\n",
    "for email_message in train_df['email_message'].astype(str):\n",
    "    word_counter.update(email_message.split())\n",
    "\n",
    "# Sort the word counts in descending order\n",
    "sorted_words = dict(sorted(word_counter.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "# Get the top 10000 most common words\n",
    "top_10000_words = dict(word_counter.most_common(10000))\n",
    "\n",
    "# Create a list of the top 10000 words for future use\n",
    "top_10000_words_list = list(top_10000_words.keys())\n",
    "\n",
    "# Display the top 10000 words\n",
    "print(\"\\nTop 10,000 Words:\")\n",
    "print(top_10000_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f17778d-a1d0-4337-befe-afab36bcb91e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
